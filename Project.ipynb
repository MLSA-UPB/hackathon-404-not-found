{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from os import listdir\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plus_dir = 'C:\\Dataset\\+'\n",
    "minus_dir = 'C:\\Dataset\\-'\n",
    "times_dir = 'C:/Dataset/times'\n",
    "plus_names = listdir(plus_dir)\n",
    "minus_names = listdir(minus_dir)\n",
    "times_names = listdir(times_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "plus_len = len([name for name in listdir(plus_dir)])\n",
    "minus_len = len([name for name in listdir(minus_dir)])\n",
    "times_len = len([name for name in listdir(times_dir)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_names = plus_names + minus_names + times_names\n",
    "train_labels = []\n",
    "for i in range(0, plus_len):\n",
    "    train_labels.append(0)\n",
    "for i in range(plus_len, plus_len + minus_len):\n",
    "    train_labels.append(1)\n",
    "for i in range(plus_len + minus_len, plus_len + minus_len + times_len):\n",
    "    train_labels.append(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plus\n"
     ]
    }
   ],
   "source": [
    "X_train = ([])\n",
    "\n",
    "for name in train_names:\n",
    "    X_train.append(cv2.imread(name, 0))\n",
    "    X_train[len(X_train) - 1] = np.reshape(X_train[len(X_train) - 1], (45, 45, 1))\n",
    "    X_train[len(X_train) - 1] = X_train[len(X_train) - 1].astype('float32')\n",
    "    X_train[len(X_train) - 1] /= 255\n",
    "X_train = tf.convert_to_tensor(X_train)\n",
    "print(train_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, plus_len):\n",
    "    train_names[i] = plus_dir + '/' + train_names[i]\n",
    "for i in range(plus_len, plus_len + minus_len):\n",
    "    train_names[i] = minus_dir + '/' + train_names[i]\n",
    "for i in range(plus_len + minus_len, plus_len + minus_len + times_len):\n",
    "    train_names[i] = times_dir + '/' + train_names[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def preprocessing(train_names):\n",
    "    X_train = tf.zeros((plus_len + minus_len + times_len))\n",
    "    for name in train_names:\n",
    "        X_train.append(cv2.imread(name, 0))\n",
    "        X_train[len(X_train) - 1] = np.reshape(X_train[len(X_train) - 1], (1, 45, 45, 1))\n",
    "        X_train[len(X_train) - 1] = X_train[len(X_train) - 1].astype('float32')\n",
    "        X_train[len(X_train) - 1] /= 255\n",
    "    return X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11434 samples\n",
      "Epoch 1/5\n",
      "11434/11434 [==============================] - 43s 4ms/sample - loss: 0.0032 - accuracy: 0.9990\n",
      "Epoch 2/5\n",
      "11434/11434 [==============================] - 42s 4ms/sample - loss: 2.7658e-04 - accuracy: 0.9999\n",
      "Epoch 3/5\n",
      "11434/11434 [==============================] - 41s 4ms/sample - loss: 6.7869e-05 - accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "11434/11434 [==============================] - 41s 4ms/sample - loss: 2.6059e-05 - accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "11434/11434 [==============================] - 40s 3ms/sample - loss: 2.4010e-05 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18d09c78f48>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.asarray(X_train)\n",
    "train_labels = np.asarray(train_labels)\n",
    "model.compile(loss = tf.keras.losses.sparse_categorical_crossentropy,\n",
    "              optimizer = 'adam',\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "model.fit(X_train, train_labels,\n",
    "        batch_size = 32,\n",
    "        epochs = 5,\n",
    "          shuffle = True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('symbols.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 43, 43, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 43, 43, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 21, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 21, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 19, 19, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 19, 19, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 19, 19, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 17, 17, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 17, 17, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 282,371\n",
      "Trainable params: 281,923\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(32, kernel_size = (3, 3),\n",
    "                activation = 'relu',\n",
    "                input_shape = (45, 45, 1)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation = 'relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation = 'relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(128, activation = 'relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dense(3, activation = 'softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('C:/Model_Symbols')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uint8\n",
      "(45, 45)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# load and display an image with Matplotlib\n",
    "from matplotlib import image\n",
    "from matplotlib import pyplot\n",
    "# load image as pixel array\n",
    "img = 'C:/Dataset/+/exp12345.jpg'\n",
    "#img = 'Downloads/canvas-img (4).png'\n",
    "image = cv2.imread(img, 0)\n",
    "# summarize shape of the pixel array\n",
    "print(image.dtype)\n",
    "print(image.shape)\n",
    "# display the array of pixels as an image\n",
    "pyplot.imshow(image)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.9971646e-01 2.4992253e-06 2.8100406e-04]]\n"
     ]
    }
   ],
   "source": [
    "image = np.reshape(image, (1, 45, 45, 1))\n",
    "image = image / 255\n",
    "pred = model.predict(image)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
