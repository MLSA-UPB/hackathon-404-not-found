{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from os import listdir\n",
    "from tensorflow.keras.preprocessing.image import load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plus_dir = 'C:\\Dataset\\+'\n",
    "minus_dir = 'C:\\Dataset\\-'\n",
    "times_dir = 'C:/Dataset/times'\n",
    "plus_names = listdir(plus_dir)\n",
    "minus_names = listdir(minus_dir)\n",
    "times_names = listdir(times_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "plus_len = len([name for name in listdir(plus_dir)])\n",
    "minus_len = len([name for name in listdir(minus_dir)])\n",
    "times_len = len([name for name in listdir(times_dir)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11434\n"
     ]
    }
   ],
   "source": [
    "train_names = plus_names + minus_names + times_names\n",
    "train_labels = []\n",
    "for i in range(0, plus_len):\n",
    "    train_labels.append('plus')\n",
    "for i in range(plus_len, plus_len + minus_len):\n",
    "    train_labels.append('minus')\n",
    "for i in range(plus_len + minus_len, plus_len + minus_len + times_len):\n",
    "    train_labels.append('times')\n",
    "print(len(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, plus_len):\n",
    "    train_names[i] = plus_dir + '/' + train_names[i]\n",
    "for i in range(plus_len, plus_len + minus_len):\n",
    "    train_names[i] = minus_dir + '/' + train_names[i]\n",
    "for i in range(plus_len + minus_len, plus_len + minus_len + times_len):\n",
    "    train_names[i] = times_dir + '/' + train_names[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:\\Dataset\\+/exp12345.jpg</td>\n",
       "      <td>plus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:\\Dataset\\+/exp12347.jpg</td>\n",
       "      <td>plus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:\\Dataset\\+/exp12348.jpg</td>\n",
       "      <td>plus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:\\Dataset\\+/exp12350.jpg</td>\n",
       "      <td>plus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:\\Dataset\\+/exp12352.jpg</td>\n",
       "      <td>plus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          id label\n",
       "0  C:\\Dataset\\+/exp12345.jpg  plus\n",
       "1  C:\\Dataset\\+/exp12347.jpg  plus\n",
       "2  C:\\Dataset\\+/exp12348.jpg  plus\n",
       "3  C:\\Dataset\\+/exp12350.jpg  plus\n",
       "4  C:\\Dataset\\+/exp12352.jpg  plus"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.DataFrame({\n",
    "    'id': train_names,\n",
    "    'label': train_labels\n",
    "})\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 222, 222, 32)      896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 222, 222, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 111, 111, 32)      0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 111, 111, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 109, 109, 32)      9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 109, 109, 32)      128       \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 109, 109, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 107, 107, 32)      9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 107, 107, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 53, 53, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 89888)             0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 128)               11505792  \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 11,526,467\n",
      "Trainable params: 11,526,019\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(32, kernel_size = (3, 3),\n",
    "                activation = 'relu',\n",
    "                input_shape = (224, 224, 3)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation = 'relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation = 'relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(128, activation = 'relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dense(3, activation = 'softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11434 validated image filenames belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "data_gen_with_aug = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.2,\n",
    "    fill_mode = 'nearest',\n",
    "    width_shift_range = 0.1,\n",
    "    height_shift_range = 0.1\n",
    ")\n",
    "\n",
    "train_generator = data_gen_with_aug.flow_from_dataframe(\n",
    "    train_df,\n",
    "    x_col='id',\n",
    "    y_col='label',\n",
    "    class_mode = 'categorical',\n",
    "    target_size = (224, 224),\n",
    "    batch_size = 16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 3 steps\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 7s 2s/step - loss: 1.1165 - accuracy: 0.6042\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.8440 - accuracy: 0.7708\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.7272 - accuracy: 0.7500\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.4865 - accuracy: 0.8333\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.4314 - accuracy: 0.8750\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.5697 - accuracy: 0.8333\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.5201 - accuracy: 0.8333\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 6s 2s/step - loss: 0.1255 - accuracy: 0.9375\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.2050 - accuracy: 0.9583\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.1976 - accuracy: 0.9167\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21a1951c848>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "from PIL import Image\n",
    "sys.modules['Image'] = Image \n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    epochs = 10,\n",
    "    shuffle = True,\n",
    "    steps_per_epoch = 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
